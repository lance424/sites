    <div class="col1">
      <h1>Analytics - Current Work</h1>
        <p>Any metric has always needed a deeper understanding about what is behind it. How can it be misread? How can it be abused? Is the right person getting acknowledgement? I started digging into this overall topic deeply in 2015. Reading and understanding the current state of the art. I had already used a player ranking system with my junior high coaching that was being used by the Memphis Grizzlies of the NBA. I knew it was on the right track, but it still sometimes missed players that were helping the team. I continued using these methods as a high school coach, but understood the limitations. I got into Krossover and Hudl and prepared evaluations of the team and of players based on what they had available to us. I had to sort out the good from the junk. (Software will add "junk" because some users want it, and will only buy it if their "hot tool" is included. Software options are about sales, not in what is valuable to the user.)


        <p>In my opinion, the biggest weakness is with the defensive aspect of the game. This is the so called Holy Grail of basketball analytics. It has been written about widely and no one appears to have a solution. In 2016, I had an idea that I thought could help. I evaluated this new tool using high school, college and Olympic games. After it appeared to be working well, I implemented it with our high school team on a trial basis during our 2016/17 season. It was showing many new things to us, and yet still confirming our coaching senses. In 2017, I further automated my system and expanded my evaluation. I reviewed top players from opposing teams. I evaluated more college teams with different styles of play. I looked at zone team, and aggressive man teams. I looked at all levels of college teams.

        <p>The feedback received has been related to areas beyond the player rating and defensive metric. I'm using this feedback to expand my approach to determining top players.

        <p>In January 2018, I expanded the metrics included in the tool. I have added additional data to collect. The purpose is to allow the rating to also point to "why" a player is strong or weak. As I worked on the overall concept, I decided to match the measures to the skills needed for each position. This last phase (position based skill evaluation) is not in place yet. After data quality issues have been reviewed and validated, it will be put into operation. The concept is outlined and partially drafted. Realistically, it will take some time to have a solid evaluation. I believe the tool will require advanced and potentially new optimization methods to properly reflect the rating.

        <p>What I have learned, it is really about providing solid input to the coach. Who is good, and why. Where can we get better, and how. Rarely do coaches care about the ratings value itself. So my focus has been on the analysis report more than anything else.


        <p>Other organizations have been working on image/ pattern recognition and slow motion replay would allow many levels of details to be assessed and addressed. This is something to keep aware of but not something I am directly working on.

    </div>
