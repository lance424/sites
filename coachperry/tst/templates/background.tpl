    <div class="col1">
      <h1>Analytics - Background</h1>
        <p>Player scoring systems have been around a long time. Coaches desire an objective way to know who is better and why. Points are awarded for rebounds, steals and of course points scored. Points are taken away for missed shots and turnovers. The elegance of the system will vary from team to team, but many coaches have a method they have become comfortable with. I remember my own coach using this when I was a junior high player. Of course, he was a high school math teacher!

        <p>With the addition of the 3 point shot, coaches became interested in a concept called "effective" shooting percentage. While we tend to make 3 pointers at a lower percentage, what is the impact of the extra point obtained from shooting it? This created a "50% increase" in shooting percentage to allow for this point difference. This pushed coaches to think at a deeper level in other aspects of the game as well.

        <p>The media has helped with this interest by reporting various other metrics. One example is the "+/-" value for an individual player. Fans enjoy this discussion about who is doing well. Some coaches will watch this metric to set lineups. Others consider it to be missing too much of the equation and do not pay attention to it. I am one who ignores it.

        <p>As computer memory grew and video recording became more available, software programs were developed to allow film sharing. This helped the assistant coaches, players, and people recruiting players. This allowed tape exchange programs to go digital.

        <p>This set the stage for an explosion of basketball analytics. After the "Moneyball" book was published (and the movie made), all sports wanted to catch up with what baseball teams were doing.

      <h2>Analytics - My Background</h2>

        <p>Any metric has always needed a deeper understanding about what is behind it. How can it be misread? How can it be abused? Is the right person getting acknowledgement for the right reasons? I started digging into this deeply in 2015. Reading and understanding the current state of the art. I had already used a player ranking system with my junior high coaching that was being used by the Memphis Grizzlies of the NBA. I knew it was on the right track, but it still missed players that were helping the team. I continued using these methods as a high school coach, but understood the limitations. I got into Krossover and Hudl and prepared evaluations of the team and of players based on what they had available. I had to sort out the good from the junk. (Software will add "junk" because some users want it, and will only buy it if their "hot tool" is included. Software options are about sales, not in what is valuable to the user.) What were we looking at the wrong way? How could we do things in a different way?

        <p>I started years earlier with an annual review of available tournament data and how they compared with winning and losing. I looked at high school and NCAA data over a 6 year period. I looked at women and men. I eventually performed a regression analysis of all the seasons combined. Simply put, I found the correlation to be weaker than expected. Very weak. Additional things were needs. Blending my engineering/ science background, my analysis experiences and my coaching view, I felt there had to be a solution. If only I could find the right unique insight.

        <p>In my opinion, the biggest weakness is with the defensive aspect of the game. This is the so called Holy Grail of basketball analytics. It has been written about widely and no one appears to have a valid solution. In 2016, I had an idea that I thought could help. I evaluated this new tool using high school, college and Olympic game data. After it appeared to be working well, I implemented it with our high school team on a trial basis during our 2016/17 season. It was showing many new things, and yet still confirming our coaching senses. In 2017, I automated my system and expanded the evaluation. I reviewed top players from opposing teams. I evaluated more college teams with different styles of play. I looked at zone teams and aggressive man teams. I looked at all levels of college teams.

        <p>I have called this approach "Behavioral Analytics" (BA) which looks more at the actions as compared to only the results of the actions. The measures need to be simple to help with data quality. While the outputs may not be expected at times, they need to never contradict our coaching insights. This is what I mean by validating the model. There needs to be feedback with the model to ensure it is tracking.

</p>

    </div>
